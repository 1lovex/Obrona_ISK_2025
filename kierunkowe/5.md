# Pytanie 5 - Ocena złożoności algorytmów

## Kuba

Złożoność algorytmu to miara ilości zasobów (**czasu** lub **pamięci**), jakie są potrzebne do rozwiązania problemu o określonym rozmiarze danych wejściowych ($n$). Złożoność nie jest stałą liczbą, lecz funkcją zależną od $n$.

### Podstawowe pojęcia

- **Problem obliczeniowy**: Ogólne zadanie do wykonania (np. posortowanie liczb).
- **Instancja problemu**: Problem z konkretnymi danymi (np. posortowanie konkretnej listy $[5, 2, 9]$).
- **Algorytm**: Skończony ciąg instrukcji prowadzący do rozwiązania problemu.

### Modele i typy złożoności

Wyróżniamy dwa główne zasoby, które podlegają ocenie:

- **Złożoność czasowa**: Określa, jak rośnie liczba operacji elementarnych wraz ze wzrostem danych. Jest to model ważniejszy w praktyce.
- **Złożoność pamięciowa**: Określa, ile dodatkowego miejsca w pamięci RAM potrzebuje algorytm do działania.

**Podział ze względu na dane wejściowe:**

- **Złożoność pesymistyczna** (Notacja $O$): Najgorszy możliwy przypadek. Gwarantuje nam, że algorytm nie zadziała wolniej niż wyznaczone ramy.
- **Złożoność optymistyczna** (Notacja $\Omega$): Najlepszy możliwy scenariusz (np. szukamy elementu, który jest na samym początku listy).
- **Złożoność średnia** (Notacja $\Theta$): Wartość oczekiwana dla typowych, losowych danych.

### Notacja asymptotyczna (Bachmanna-Landaua)

Służy do opisu tempa wzrostu funkcji złożoności bez wnikania w szczegóły sprzętowe (np. moc procesora).

- **$O$ (duże O)**: Górna granica ("nie wolniej niż"). Najczęściej używana w informatyce do opisu najgorszego przypadku.
- **$\Omega$ (Omega)**: Dolna granica ("nie szybciej niż").
- **$\Theta$ (Theta)**: Oszacowanie dokładne (funkcja rośnie w takim samym tempie jak wzorzec).

### Klasy i rzędy złożoności (Od najszybszych do najwolniejszych)

| Notacja       | Nazwa         | Przykład                                                                      |
| ------------- | ------------- | ----------------------------------------------------------------------------- |
| $O(1)$        | Stała         | Sprawdzenie czy liczba jest parzysta, dostęp do elementu tablicy po indeksie. |
| $O(\log n)$   | Logarytmiczna | Wyszukiwanie binarne w posortowanej tablicy.                                  |
| $O(n)$        | Liniowa       | Przeszukanie nieposortowanej tablicy w poszukiwaniu minimum.                  |
| $O(n \log n)$ | Quasi-liniowa | Wydajne algorytmy sortowania (MergeSort, QuickSort).                          |
| $O(n^2)$      | Kwadratowa    | Proste sortowania (Bąbelkowe, przez wstawianie).                              |
| $O(n^k)$      | Wielomianowa  | Mnożenie macierzy, programowanie liniowe.                                     |
| $O(2^n)$      | Wykładnicza   | Problem komiwojażera (algorytmy dynamiczne).                                  |
| $O(n!)$       | Silnia        | Problem komiwojażera metodą brutalną (sprawdzanie wszystkich permutacji).     |

### Klasy problemów (P i NP)

Problemy dzielimy na grupy w zależności od tego, jak trudne jest ich rozwiązanie:

- **Klasa P (Polynomial)**: Problemy, które potrafimy rozwiązać w czasie wielomianowym (szybko). Przykład: Sortowanie.
- **Klasa NP (Nondeterministic Polynomial)**: Problemy, dla których potrafimy w czasie wielomianowym jedynie sprawdzić, czy podane rozwiązanie jest poprawne.
- **Klasa NP-zupełna**: Najtrudniejsze problemy w klasie NP. Jeśli znaleźlibyśmy szybki sposób na jeden z nich, rozwiązalibyśmy wszystkie problemy NP.
- **Klasa NP-trudna**: Problemy co najmniej tak trudne jak NP-zupełne, ale niekoniecznie należące do klasy NP (nie muszą być problemami decyzyjnymi).

### Podsumowanie na obrone

Podczas oceny algorytmu nie interesuje nas dokładny czas w sekundach, ponieważ zależy on od sprzętu. Interesuje nas asymptotyczne tempo wzrostu, czyli to, jak zachowa się algorytm, gdy dane wejściowe urosną milionkrotnie. Najważniejszym parametrem jest zazwyczaj pesymistyczna złożoność czasowa, bo pozwala ona przewidzieć "bezpieczny" czas wykonania zadania.

## Stachu

[Wikipedia](https://pl.wikipedia.org/wiki/Asymptotyczne_tempo_wzrostu#Definicje_analityczne)

### Duże O

Funkcja $f(n) = O(g(n))$ wtedy i tylko wtedy, gdy istnieją stałe $c > 0$ i $n_0 > 0$ takie, że dla każdego $n > n_0$: $f(n) \leq c \cdot g(n)$.

Notacja $O$ pozwala określić maksymalny możliwy wzrost czasu działania algorytmu.

### Małe o

Funkcja $f(n) = o(g(n))$ wtedy i tylko wtedy, gdy dla każdej stałej $c > 0$ istnieje $n_0 > 0$, takie, że dla każdego $n > n_0$: $f(n) < c \cdot g(n)$.

Oznacza, że $g(n)$ jest ściśle większym rzędem wzrostu niż $f(n)$ – czyli $f(n)$ rośnie znacznie wolniej.

### Duże Ω

Funkcja $f(n) = \Omega(g(n))$ wtedy i tylko wtedy, gdy istnieją stałe $c > 0$ i $n_0 > 0$, takie, że dla każdego $n > n_0$: $f(n) \geq c \cdot g(n)$.

Notacja $\Omega$ służy do określenia najlepszego możliwego przypadku (best case) lub teoretycznego minimum złożoności.

### Małe ω

Funkcja $f(n) = \omega(g(n))$ wtedy i tylko wtedy, gdy dla każdej stałej $c > 0$ istnieje $n_0 > 0$, takie, że dla każdego $n > n_0$: $f(n) > c \cdot g(n)$.

Funkcja $f(n)$ ma ściśle większy rząd wzrostu niż $g(n)$.

### Θ

Funkcja $f(n) = \Theta(g(n))$ wtedy i tylko wtedy, gdy istnieją stałe $c_1, c_2 > 0$ oraz $n_0 > 0$, takie, że dla każdego $n > n_0$: $c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n)$.

Oznacza to, że $g(n)$ stanowi dokładną asymptotyczną charakterystykę wzrostu $f(n)$ – ani nie rośnie szybciej, ani wolniej.
